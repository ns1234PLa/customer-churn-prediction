{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb7cbf9",
   "metadata": {},
   "source": [
    "| Output File                   | Description                                             | Format |\n",
    "| ----------------------------- | ------------------------------------------------------- | ------ |\n",
    "| all_customers_predictions.csv | Predictions and probabilities for each customer         | CSV    |\n",
    "| shap_all_customers.csv        | Customer, predictions, probabilities, SHAP explanations | CSV    |\n",
    "| shap_all_customers.json       | Same as above, formatted for UI/API                     | JSON   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9735b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all customer predictions for full dataset.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# 1. Load full feature set for all customers (excluding target column if present)\n",
    "X_full = pd.read_csv('customer_churn_features_with_nlp_ready.csv')\n",
    "\n",
    "# 2. Load customer IDs from processed CSV (ensure order aligns with X_full)\n",
    "customer_ids = pd.read_csv('processed_customer_churn_data_with_feedback.csv')['customerID']\n",
    "\n",
    "# 3. Load your trained model from the models/ directory\n",
    "model = joblib.load('../models/best_xgb_model.pkl')\n",
    "\n",
    "# 4. Predict churn for all customers\n",
    "churn_preds = model.predict(X_full)\n",
    "churn_probs = model.predict_proba(X_full)[:, 1]\n",
    "\n",
    "# 5. Combine into DataFrame\n",
    "df_all_preds = pd.DataFrame({\n",
    "    'customerID': customer_ids,\n",
    "    'churn_prediction': churn_preds,\n",
    "    'churn_probability': churn_probs\n",
    "})\n",
    "\n",
    "# 6. Save output to CSV (for UI, dashboards, etc.)\n",
    "df_all_preds.to_csv('all_customers_predictions.csv', index=False)\n",
    "\n",
    "print(\"Saved all customer predictions for full dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30a85193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset SHAP explanations and predictions saved without duplication.\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "# Load full dataset features and customer IDs\n",
    "X_full = pd.read_csv('customer_churn_features_with_nlp_ready.csv')\n",
    "customer_ids = pd.read_csv('processed_customer_churn_data_with_feedback.csv')['customerID']\n",
    "\n",
    "# Load trained XGBoost model\n",
    "model = joblib.load('../models/best_xgb_model.pkl')\n",
    "\n",
    "# Predict churn on the full dataset\n",
    "churn_preds = model.predict(X_full)\n",
    "churn_probs = model.predict_proba(X_full)[:, 1]\n",
    "\n",
    "# Initialize SHAP explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Compute SHAP values for the full dataset (this may be time-consuming)\n",
    "shap_values = explainer.shap_values(X_full)\n",
    "\n",
    "# Determine top 5 SHAP features per customer\n",
    "shap_abs = np.abs(shap_values)\n",
    "top_indices = np.argsort(-shap_abs, axis=1)[:, :5]\n",
    "feature_names = X_full.columns\n",
    "\n",
    "top_shap_features = []\n",
    "for i, feature_idxs in enumerate(top_indices):\n",
    "    features = feature_names[feature_idxs].tolist()\n",
    "    values = shap_values[i, feature_idxs].tolist()\n",
    "    top_shap_features.append({\"features\": features, \"values\": values})\n",
    "\n",
    "# Combine results with customer IDs\n",
    "df_shap = pd.DataFrame({\n",
    "    'customerID': customer_ids,\n",
    "    'churn_prediction': churn_preds,\n",
    "    'churn_probability': churn_probs,\n",
    "    'top_shap_features': top_shap_features\n",
    "})\n",
    "\n",
    "# Paths for output files\n",
    "json_path = '../metrics/shap_all_customers.json'\n",
    "csv_path = '../metrics/shap_all_customers.csv'\n",
    "\n",
    "# Remove existing files if they exist to avoid duplicate appends\n",
    "if os.path.exists(json_path):\n",
    "    os.remove(json_path)\n",
    "if os.path.exists(csv_path):\n",
    "    os.remove(csv_path)\n",
    "\n",
    "# Save SHAP explanations and predictions to valid JSON array and CSV\n",
    "df_shap.to_json(json_path, orient='records', indent=4)\n",
    "\n",
    "df_shap.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"Full dataset SHAP explanations and predictions saved without duplication.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
